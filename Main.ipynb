{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb99772-c49c-48dc-89c0-c628d38548fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, Dense, Flatten, Multiply, Dropout\n",
    ")\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import jolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6c0e336-ff3b-4f36-9f9f-01273cbeb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Obfuscated-MalMem2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd74888-9186-4542-a6b5-f021db4212b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>pslist.nproc</th>\n",
       "      <th>pslist.nppid</th>\n",
       "      <th>pslist.avg_threads</th>\n",
       "      <th>pslist.nprocs64bit</th>\n",
       "      <th>pslist.avg_handlers</th>\n",
       "      <th>dlllist.ndlls</th>\n",
       "      <th>dlllist.avg_dlls_per_proc</th>\n",
       "      <th>handles.nhandles</th>\n",
       "      <th>handles.avg_handles_per_proc</th>\n",
       "      <th>...</th>\n",
       "      <th>svcscan.kernel_drivers</th>\n",
       "      <th>svcscan.fs_drivers</th>\n",
       "      <th>svcscan.process_services</th>\n",
       "      <th>svcscan.shared_process_services</th>\n",
       "      <th>svcscan.interactive_process_services</th>\n",
       "      <th>svcscan.nactive</th>\n",
       "      <th>callbacks.ncallbacks</th>\n",
       "      <th>callbacks.nanonymous</th>\n",
       "      <th>callbacks.ngeneric</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benign</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>10.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>202.844444</td>\n",
       "      <td>1694</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>9129</td>\n",
       "      <td>212.302326</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benign</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>11.531915</td>\n",
       "      <td>0</td>\n",
       "      <td>242.234043</td>\n",
       "      <td>2074</td>\n",
       "      <td>44.127660</td>\n",
       "      <td>11385</td>\n",
       "      <td>242.234043</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benign</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>14.725000</td>\n",
       "      <td>0</td>\n",
       "      <td>288.225000</td>\n",
       "      <td>1932</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>11529</td>\n",
       "      <td>288.225000</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benign</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>264.281250</td>\n",
       "      <td>1445</td>\n",
       "      <td>45.156250</td>\n",
       "      <td>8457</td>\n",
       "      <td>264.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benign</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>11.452381</td>\n",
       "      <td>0</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>2067</td>\n",
       "      <td>49.214286</td>\n",
       "      <td>11816</td>\n",
       "      <td>281.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  pslist.nproc  pslist.nppid  pslist.avg_threads  \\\n",
       "0   Benign            45            17           10.555556   \n",
       "1   Benign            47            19           11.531915   \n",
       "2   Benign            40            14           14.725000   \n",
       "3   Benign            32            13           13.500000   \n",
       "4   Benign            42            16           11.452381   \n",
       "\n",
       "   pslist.nprocs64bit  pslist.avg_handlers  dlllist.ndlls  \\\n",
       "0                   0           202.844444           1694   \n",
       "1                   0           242.234043           2074   \n",
       "2                   0           288.225000           1932   \n",
       "3                   0           264.281250           1445   \n",
       "4                   0           281.333333           2067   \n",
       "\n",
       "   dlllist.avg_dlls_per_proc  handles.nhandles  handles.avg_handles_per_proc  \\\n",
       "0                  38.500000              9129                    212.302326   \n",
       "1                  44.127660             11385                    242.234043   \n",
       "2                  48.300000             11529                    288.225000   \n",
       "3                  45.156250              8457                    264.281250   \n",
       "4                  49.214286             11816                    281.333333   \n",
       "\n",
       "   ...  svcscan.kernel_drivers  svcscan.fs_drivers  svcscan.process_services  \\\n",
       "0  ...                     221                  26                        24   \n",
       "1  ...                     222                  26                        24   \n",
       "2  ...                     222                  26                        27   \n",
       "3  ...                     222                  26                        27   \n",
       "4  ...                     222                  26                        24   \n",
       "\n",
       "   svcscan.shared_process_services  svcscan.interactive_process_services  \\\n",
       "0                              116                                     0   \n",
       "1                              118                                     0   \n",
       "2                              118                                     0   \n",
       "3                              118                                     0   \n",
       "4                              118                                     0   \n",
       "\n",
       "   svcscan.nactive  callbacks.ncallbacks  callbacks.nanonymous  \\\n",
       "0              121                    87                     0   \n",
       "1              122                    87                     0   \n",
       "2              120                    88                     0   \n",
       "3              120                    88                     0   \n",
       "4              124                    87                     0   \n",
       "\n",
       "   callbacks.ngeneric   Class  \n",
       "0                   8  Benign  \n",
       "1                   8  Benign  \n",
       "2                   8  Benign  \n",
       "3                   8  Benign  \n",
       "4                   8  Benign  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d5717f-c6c5-4cad-8f85-ac5e14292056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58596 entries, 0 to 58595\n",
      "Data columns (total 57 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Category                                58596 non-null  object \n",
      " 1   pslist.nproc                            58596 non-null  int64  \n",
      " 2   pslist.nppid                            58596 non-null  int64  \n",
      " 3   pslist.avg_threads                      58596 non-null  float64\n",
      " 4   pslist.nprocs64bit                      58596 non-null  int64  \n",
      " 5   pslist.avg_handlers                     58596 non-null  float64\n",
      " 6   dlllist.ndlls                           58596 non-null  int64  \n",
      " 7   dlllist.avg_dlls_per_proc               58596 non-null  float64\n",
      " 8   handles.nhandles                        58596 non-null  int64  \n",
      " 9   handles.avg_handles_per_proc            58596 non-null  float64\n",
      " 10  handles.nport                           58596 non-null  int64  \n",
      " 11  handles.nfile                           58596 non-null  int64  \n",
      " 12  handles.nevent                          58596 non-null  int64  \n",
      " 13  handles.ndesktop                        58596 non-null  int64  \n",
      " 14  handles.nkey                            58596 non-null  int64  \n",
      " 15  handles.nthread                         58596 non-null  int64  \n",
      " 16  handles.ndirectory                      58596 non-null  int64  \n",
      " 17  handles.nsemaphore                      58596 non-null  int64  \n",
      " 18  handles.ntimer                          58596 non-null  int64  \n",
      " 19  handles.nsection                        58596 non-null  int64  \n",
      " 20  handles.nmutant                         58596 non-null  int64  \n",
      " 21  ldrmodules.not_in_load                  58596 non-null  int64  \n",
      " 22  ldrmodules.not_in_init                  58596 non-null  int64  \n",
      " 23  ldrmodules.not_in_mem                   58596 non-null  int64  \n",
      " 24  ldrmodules.not_in_load_avg              58596 non-null  float64\n",
      " 25  ldrmodules.not_in_init_avg              58596 non-null  float64\n",
      " 26  ldrmodules.not_in_mem_avg               58596 non-null  float64\n",
      " 27  malfind.ninjections                     58596 non-null  int64  \n",
      " 28  malfind.commitCharge                    58596 non-null  int64  \n",
      " 29  malfind.protection                      58596 non-null  int64  \n",
      " 30  malfind.uniqueInjections                58596 non-null  float64\n",
      " 31  psxview.not_in_pslist                   58596 non-null  int64  \n",
      " 32  psxview.not_in_eprocess_pool            58596 non-null  int64  \n",
      " 33  psxview.not_in_ethread_pool             58596 non-null  int64  \n",
      " 34  psxview.not_in_pspcid_list              58596 non-null  int64  \n",
      " 35  psxview.not_in_csrss_handles            58596 non-null  int64  \n",
      " 36  psxview.not_in_session                  58596 non-null  int64  \n",
      " 37  psxview.not_in_deskthrd                 58596 non-null  int64  \n",
      " 38  psxview.not_in_pslist_false_avg         58596 non-null  float64\n",
      " 39  psxview.not_in_eprocess_pool_false_avg  58596 non-null  float64\n",
      " 40  psxview.not_in_ethread_pool_false_avg   58596 non-null  float64\n",
      " 41  psxview.not_in_pspcid_list_false_avg    58596 non-null  float64\n",
      " 42  psxview.not_in_csrss_handles_false_avg  58596 non-null  float64\n",
      " 43  psxview.not_in_session_false_avg        58596 non-null  float64\n",
      " 44  psxview.not_in_deskthrd_false_avg       58596 non-null  float64\n",
      " 45  modules.nmodules                        58596 non-null  int64  \n",
      " 46  svcscan.nservices                       58596 non-null  int64  \n",
      " 47  svcscan.kernel_drivers                  58596 non-null  int64  \n",
      " 48  svcscan.fs_drivers                      58596 non-null  int64  \n",
      " 49  svcscan.process_services                58596 non-null  int64  \n",
      " 50  svcscan.shared_process_services         58596 non-null  int64  \n",
      " 51  svcscan.interactive_process_services    58596 non-null  int64  \n",
      " 52  svcscan.nactive                         58596 non-null  int64  \n",
      " 53  callbacks.ncallbacks                    58596 non-null  int64  \n",
      " 54  callbacks.nanonymous                    58596 non-null  int64  \n",
      " 55  callbacks.ngeneric                      58596 non-null  int64  \n",
      " 56  Class                                   58596 non-null  object \n",
      "dtypes: float64(15), int64(40), object(2)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "614b9b59-dbc6-4788-9120-ebc3db19258a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category                                  0\n",
       "pslist.nproc                              0\n",
       "pslist.nppid                              0\n",
       "pslist.avg_threads                        0\n",
       "pslist.nprocs64bit                        0\n",
       "pslist.avg_handlers                       0\n",
       "dlllist.ndlls                             0\n",
       "dlllist.avg_dlls_per_proc                 0\n",
       "handles.nhandles                          0\n",
       "handles.avg_handles_per_proc              0\n",
       "handles.nport                             0\n",
       "handles.nfile                             0\n",
       "handles.nevent                            0\n",
       "handles.ndesktop                          0\n",
       "handles.nkey                              0\n",
       "handles.nthread                           0\n",
       "handles.ndirectory                        0\n",
       "handles.nsemaphore                        0\n",
       "handles.ntimer                            0\n",
       "handles.nsection                          0\n",
       "handles.nmutant                           0\n",
       "ldrmodules.not_in_load                    0\n",
       "ldrmodules.not_in_init                    0\n",
       "ldrmodules.not_in_mem                     0\n",
       "ldrmodules.not_in_load_avg                0\n",
       "ldrmodules.not_in_init_avg                0\n",
       "ldrmodules.not_in_mem_avg                 0\n",
       "malfind.ninjections                       0\n",
       "malfind.commitCharge                      0\n",
       "malfind.protection                        0\n",
       "malfind.uniqueInjections                  0\n",
       "psxview.not_in_pslist                     0\n",
       "psxview.not_in_eprocess_pool              0\n",
       "psxview.not_in_ethread_pool               0\n",
       "psxview.not_in_pspcid_list                0\n",
       "psxview.not_in_csrss_handles              0\n",
       "psxview.not_in_session                    0\n",
       "psxview.not_in_deskthrd                   0\n",
       "psxview.not_in_pslist_false_avg           0\n",
       "psxview.not_in_eprocess_pool_false_avg    0\n",
       "psxview.not_in_ethread_pool_false_avg     0\n",
       "psxview.not_in_pspcid_list_false_avg      0\n",
       "psxview.not_in_csrss_handles_false_avg    0\n",
       "psxview.not_in_session_false_avg          0\n",
       "psxview.not_in_deskthrd_false_avg         0\n",
       "modules.nmodules                          0\n",
       "svcscan.nservices                         0\n",
       "svcscan.kernel_drivers                    0\n",
       "svcscan.fs_drivers                        0\n",
       "svcscan.process_services                  0\n",
       "svcscan.shared_process_services           0\n",
       "svcscan.interactive_process_services      0\n",
       "svcscan.nactive                           0\n",
       "callbacks.ncallbacks                      0\n",
       "callbacks.nanonymous                      0\n",
       "callbacks.ngeneric                        0\n",
       "Class                                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca148d7-d3c3-4124-a3d7-5a98f6feabf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pslist.nproc</th>\n",
       "      <th>pslist.nppid</th>\n",
       "      <th>pslist.avg_threads</th>\n",
       "      <th>pslist.nprocs64bit</th>\n",
       "      <th>pslist.avg_handlers</th>\n",
       "      <th>dlllist.ndlls</th>\n",
       "      <th>dlllist.avg_dlls_per_proc</th>\n",
       "      <th>handles.nhandles</th>\n",
       "      <th>handles.avg_handles_per_proc</th>\n",
       "      <th>handles.nport</th>\n",
       "      <th>...</th>\n",
       "      <th>svcscan.nservices</th>\n",
       "      <th>svcscan.kernel_drivers</th>\n",
       "      <th>svcscan.fs_drivers</th>\n",
       "      <th>svcscan.process_services</th>\n",
       "      <th>svcscan.shared_process_services</th>\n",
       "      <th>svcscan.interactive_process_services</th>\n",
       "      <th>svcscan.nactive</th>\n",
       "      <th>callbacks.ncallbacks</th>\n",
       "      <th>callbacks.nanonymous</th>\n",
       "      <th>callbacks.ngeneric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.0</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>5.859600e+04</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.0</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "      <td>58596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.394771</td>\n",
       "      <td>14.713837</td>\n",
       "      <td>11.341655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247.509819</td>\n",
       "      <td>1810.805447</td>\n",
       "      <td>43.707806</td>\n",
       "      <td>1.025858e+04</td>\n",
       "      <td>249.560958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>391.347549</td>\n",
       "      <td>221.406581</td>\n",
       "      <td>25.996245</td>\n",
       "      <td>25.063417</td>\n",
       "      <td>116.879514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.995546</td>\n",
       "      <td>86.905659</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>7.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.777249</td>\n",
       "      <td>2.656748</td>\n",
       "      <td>1.588231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.857790</td>\n",
       "      <td>329.782639</td>\n",
       "      <td>5.742023</td>\n",
       "      <td>4.866864e+03</td>\n",
       "      <td>145.999866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.529704</td>\n",
       "      <td>1.991087</td>\n",
       "      <td>0.170790</td>\n",
       "      <td>1.529628</td>\n",
       "      <td>1.550401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.822858</td>\n",
       "      <td>3.134117</td>\n",
       "      <td>0.029199</td>\n",
       "      <td>0.010929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.962500</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>3.514000e+03</td>\n",
       "      <td>71.139241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.972973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.725000</td>\n",
       "      <td>1556.000000</td>\n",
       "      <td>38.833333</td>\n",
       "      <td>8.393000e+03</td>\n",
       "      <td>209.648228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.963710</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>42.781524</td>\n",
       "      <td>9.287500e+03</td>\n",
       "      <td>247.208951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.861955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.974322</td>\n",
       "      <td>2087.000000</td>\n",
       "      <td>49.605280</td>\n",
       "      <td>1.219300e+04</td>\n",
       "      <td>291.355050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>240.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>16.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24845.951220</td>\n",
       "      <td>3443.000000</td>\n",
       "      <td>53.170732</td>\n",
       "      <td>1.047310e+06</td>\n",
       "      <td>33784.193550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pslist.nproc  pslist.nppid  pslist.avg_threads  pslist.nprocs64bit  \\\n",
       "count  58596.000000  58596.000000        58596.000000             58596.0   \n",
       "mean      41.394771     14.713837           11.341655                 0.0   \n",
       "std        5.777249      2.656748            1.588231                 0.0   \n",
       "min       21.000000      8.000000            1.650000                 0.0   \n",
       "25%       40.000000     12.000000            9.972973                 0.0   \n",
       "50%       41.000000     15.000000           11.000000                 0.0   \n",
       "75%       43.000000     16.000000           12.861955                 0.0   \n",
       "max      240.000000     72.000000           16.818182                 0.0   \n",
       "\n",
       "       pslist.avg_handlers  dlllist.ndlls  dlllist.avg_dlls_per_proc  \\\n",
       "count         58596.000000   58596.000000               58596.000000   \n",
       "mean            247.509819    1810.805447                  43.707806   \n",
       "std             111.857790     329.782639                   5.742023   \n",
       "min              34.962500     670.000000                   7.333333   \n",
       "25%             208.725000    1556.000000                  38.833333   \n",
       "50%             243.963710    1735.000000                  42.781524   \n",
       "75%             289.974322    2087.000000                  49.605280   \n",
       "max           24845.951220    3443.000000                  53.170732   \n",
       "\n",
       "       handles.nhandles  handles.avg_handles_per_proc  handles.nport  ...  \\\n",
       "count      5.859600e+04                  58596.000000        58596.0  ...   \n",
       "mean       1.025858e+04                    249.560958            0.0  ...   \n",
       "std        4.866864e+03                    145.999866            0.0  ...   \n",
       "min        3.514000e+03                     71.139241            0.0  ...   \n",
       "25%        8.393000e+03                    209.648228            0.0  ...   \n",
       "50%        9.287500e+03                    247.208951            0.0  ...   \n",
       "75%        1.219300e+04                    291.355050            0.0  ...   \n",
       "max        1.047310e+06                  33784.193550            0.0  ...   \n",
       "\n",
       "       svcscan.nservices  svcscan.kernel_drivers  svcscan.fs_drivers  \\\n",
       "count       58596.000000            58596.000000        58596.000000   \n",
       "mean          391.347549              221.406581           25.996245   \n",
       "std             4.529704                1.991087            0.170790   \n",
       "min            94.000000               55.000000            6.000000   \n",
       "25%           389.000000              221.000000           26.000000   \n",
       "50%           389.000000              221.000000           26.000000   \n",
       "75%           395.000000              222.000000           26.000000   \n",
       "max           395.000000              222.000000           26.000000   \n",
       "\n",
       "       svcscan.process_services  svcscan.shared_process_services  \\\n",
       "count              58596.000000                     58596.000000   \n",
       "mean                  25.063417                       116.879514   \n",
       "std                    1.529628                         1.550401   \n",
       "min                    7.000000                        26.000000   \n",
       "25%                   24.000000                       116.000000   \n",
       "50%                   24.000000                       116.000000   \n",
       "75%                   27.000000                       118.000000   \n",
       "max                   27.000000                       118.000000   \n",
       "\n",
       "       svcscan.interactive_process_services  svcscan.nactive  \\\n",
       "count                               58596.0     58596.000000   \n",
       "mean                                    0.0       121.995546   \n",
       "std                                     0.0         2.822858   \n",
       "min                                     0.0        30.000000   \n",
       "25%                                     0.0       121.000000   \n",
       "50%                                     0.0       122.000000   \n",
       "75%                                     0.0       123.000000   \n",
       "max                                     0.0       129.000000   \n",
       "\n",
       "       callbacks.ncallbacks  callbacks.nanonymous  callbacks.ngeneric  \n",
       "count          58596.000000          58596.000000        58596.000000  \n",
       "mean              86.905659              0.000853            7.999881  \n",
       "std                3.134117              0.029199            0.010929  \n",
       "min               50.000000              0.000000            7.000000  \n",
       "25%               87.000000              0.000000            8.000000  \n",
       "50%               87.000000              0.000000            8.000000  \n",
       "75%               88.000000              0.000000            8.000000  \n",
       "max               89.000000              1.000000            8.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0846e103-5acd-45b9-94b5-bb55a75cd2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'pslist.nproc', 'pslist.nppid', 'pslist.avg_threads',\n",
       "       'pslist.nprocs64bit', 'pslist.avg_handlers', 'dlllist.ndlls',\n",
       "       'dlllist.avg_dlls_per_proc', 'handles.nhandles',\n",
       "       'handles.avg_handles_per_proc', 'handles.nport', 'handles.nfile',\n",
       "       'handles.nevent', 'handles.ndesktop', 'handles.nkey', 'handles.nthread',\n",
       "       'handles.ndirectory', 'handles.nsemaphore', 'handles.ntimer',\n",
       "       'handles.nsection', 'handles.nmutant', 'ldrmodules.not_in_load',\n",
       "       'ldrmodules.not_in_init', 'ldrmodules.not_in_mem',\n",
       "       'ldrmodules.not_in_load_avg', 'ldrmodules.not_in_init_avg',\n",
       "       'ldrmodules.not_in_mem_avg', 'malfind.ninjections',\n",
       "       'malfind.commitCharge', 'malfind.protection',\n",
       "       'malfind.uniqueInjections', 'psxview.not_in_pslist',\n",
       "       'psxview.not_in_eprocess_pool', 'psxview.not_in_ethread_pool',\n",
       "       'psxview.not_in_pspcid_list', 'psxview.not_in_csrss_handles',\n",
       "       'psxview.not_in_session', 'psxview.not_in_deskthrd',\n",
       "       'psxview.not_in_pslist_false_avg',\n",
       "       'psxview.not_in_eprocess_pool_false_avg',\n",
       "       'psxview.not_in_ethread_pool_false_avg',\n",
       "       'psxview.not_in_pspcid_list_false_avg',\n",
       "       'psxview.not_in_csrss_handles_false_avg',\n",
       "       'psxview.not_in_session_false_avg', 'psxview.not_in_deskthrd_false_avg',\n",
       "       'modules.nmodules', 'svcscan.nservices', 'svcscan.kernel_drivers',\n",
       "       'svcscan.fs_drivers', 'svcscan.process_services',\n",
       "       'svcscan.shared_process_services',\n",
       "       'svcscan.interactive_process_services', 'svcscan.nactive',\n",
       "       'callbacks.ncallbacks', 'callbacks.nanonymous', 'callbacks.ngeneric',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35eb6c8a-d063-436f-b6d4-d9088021212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, use_pca = True, use_smote=True, pca_components = 50):\n",
    "    if 'Category' in df.columns:\n",
    "        df.drop(columns='Category', axis=1, inplace=True)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df['Class'] = le.fit_transform(df['Class'])\n",
    "\n",
    "    x = df.drop('Class',axis=1)\n",
    "    y=df['Class']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        x_scaled = pca.fit_transform(x_scaled)\n",
    "\n",
    "    if use_smote:\n",
    "        smote = SMOTE(random_state = 42)\n",
    "        x_scaled, y = smote.fit_resample(x_scaled, y)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, stratify = y, random_state = 42)\n",
    "\n",
    "    return np.expand_dims(x_train, -1), np.expand_dims(x_test, -1), y_train, y_test, x_scaled.shape[1], le,scaler, pca if use_pca else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d14f440-e115-49b2-beff-fe72b6b57260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.79297301e+00]\n",
      "  [-1.65285237e+00]\n",
      "  [-1.16057178e+00]\n",
      "  ...\n",
      "  [ 1.14707006e-03]\n",
      "  [-5.57489760e-05]\n",
      "  [ 3.13303729e-04]]\n",
      "\n",
      " [[ 5.33306477e+00]\n",
      "  [-8.97012473e-01]\n",
      "  [-4.79682672e-02]\n",
      "  ...\n",
      "  [ 2.82366129e-03]\n",
      "  [ 1.67667089e-04]\n",
      "  [ 1.76037072e-04]]\n",
      "\n",
      " [[-7.04786176e+00]\n",
      "  [-4.61584710e+00]\n",
      "  [ 2.38438938e+00]\n",
      "  ...\n",
      "  [ 1.01862397e-03]\n",
      "  [ 3.37238881e-03]\n",
      "  [ 2.36227581e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.74509129e+00]\n",
      "  [ 3.08745013e-01]\n",
      "  [-1.61912761e+00]\n",
      "  ...\n",
      "  [ 5.04310554e-04]\n",
      "  [ 3.16024588e-04]\n",
      "  [-1.99062006e-04]]\n",
      "\n",
      " [[ 4.93541977e+00]\n",
      "  [-1.05006771e+00]\n",
      "  [-4.16731603e-01]\n",
      "  ...\n",
      "  [ 1.73394827e-03]\n",
      "  [ 8.38986416e-05]\n",
      "  [-2.25316499e-04]]\n",
      "\n",
      " [[-8.92359530e+00]\n",
      "  [-4.71755822e+00]\n",
      "  [-4.04519556e+00]\n",
      "  ...\n",
      "  [ 4.16874011e-03]\n",
      "  [ 3.70706107e-03]\n",
      "  [ 8.26678810e-04]]]\n",
      "\n",
      "\n",
      "\n",
      "[[[-2.73358537e+00]\n",
      "  [-1.50224945e+00]\n",
      "  [ 7.30320485e-01]\n",
      "  ...\n",
      "  [ 4.35188932e-04]\n",
      "  [ 5.08456881e-04]\n",
      "  [ 5.44254883e-05]]\n",
      "\n",
      " [[-1.41537833e+00]\n",
      "  [-2.37983888e+00]\n",
      "  [ 8.78526633e-01]\n",
      "  ...\n",
      "  [ 2.10245713e-03]\n",
      "  [ 1.18943442e-03]\n",
      "  [ 1.30328034e-04]]\n",
      "\n",
      " [[ 5.05006182e+00]\n",
      "  [ 2.34790239e-01]\n",
      "  [-1.18192970e-01]\n",
      "  ...\n",
      "  [ 3.45904948e-03]\n",
      "  [ 2.51772057e-04]\n",
      "  [-8.86707932e-06]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.32799719e+00]\n",
      "  [ 1.14700544e+00]\n",
      "  [-9.16249489e-01]\n",
      "  ...\n",
      "  [ 1.14716275e-03]\n",
      "  [ 6.31720709e-04]\n",
      "  [-2.79337963e-05]]\n",
      "\n",
      " [[-2.11206203e+00]\n",
      "  [-9.82484817e-01]\n",
      "  [ 8.36597764e-01]\n",
      "  ...\n",
      "  [-3.45162097e-04]\n",
      "  [ 2.21388268e-04]\n",
      "  [-2.22757175e-04]]\n",
      "\n",
      " [[-3.78736673e+00]\n",
      "  [ 2.63634743e+00]\n",
      "  [-4.80833374e-01]\n",
      "  ...\n",
      "  [ 2.08313995e-05]\n",
      "  [-1.38331357e-04]\n",
      "  [-2.97501962e-04]]]\n",
      "\n",
      "\n",
      "\n",
      "9434     0\n",
      "26912    0\n",
      "47022    1\n",
      "19371    0\n",
      "17129    0\n",
      "        ..\n",
      "1265     0\n",
      "15553    0\n",
      "26024    0\n",
      "19226    0\n",
      "42291    1\n",
      "Name: Class, Length: 46876, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "50843    1\n",
      "37832    1\n",
      "6645     0\n",
      "27932    0\n",
      "28932    0\n",
      "        ..\n",
      "4360     0\n",
      "47626    1\n",
      "32985    1\n",
      "51061    1\n",
      "51351    1\n",
      "Name: Class, Length: 11720, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "50\n",
      "\n",
      "\n",
      "\n",
      "LabelEncoder()\n",
      "\n",
      "\n",
      "\n",
      "StandardScaler()\n",
      "\n",
      "\n",
      "\n",
      "PCA(n_components=50)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in preprocess_data(df):\n",
    "    print(i)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0600f0b4-2db0-42ea-9d99-d083a6d04000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(inputs):\n",
    "    attention = Dense(inputs.shape[-1], activation='softmax')(inputs)\n",
    "    return Multiply()([inputs, attention])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b82aa397-f052-49d6-97b3-c00ecb1e891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, num_classes, use_attention=True):\n",
    "    inputs = Input(shape=(input_dim, 1))\n",
    "\n",
    "    x = Conv1D(512, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    x = Conv1D(256, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "\n",
    "    if use_attention:\n",
    "        x = attention_block(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    for units in [128, 128, 64, 64, 32, 32]:\n",
    "        x = Dense(units, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "\n",
    "    if num_classes == 2:\n",
    "        output = Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        output = Dense(num_classes, activation='softmax')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1ae3cfe-6c7f-49b2-af92-b9cfb301f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, le, tag=\"\"):\n",
    "    preds = model.predict(X_test)\n",
    "    if preds.shape[1] == 1:\n",
    "        preds_cls = (preds > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        preds_cls = np.argmax(preds, axis=1)\n",
    "\n",
    "    print(f\"\\nðŸ“Š Classification Report: {tag}\\n\")\n",
    "    print(classification_report(y_test, preds_cls, target_names=le.classes_))\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds_cls)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f\"Confusion Matrix - {tag}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50cd7d86-71ac-4056-9472-f07d57052f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(df, use_pca=True, use_smote=True, use_attention=True, tag=\"Full_Model\"):\n",
    "    print(f\"\\nðŸš€ Training: {tag}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test, input_dim, le, scaler, pca = preprocess_data(df, use_pca, use_smote)\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    model = build_model(input_dim, num_classes, use_attention)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(f\"{tag}_model.h5\", save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "    model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=32, callbacks=[checkpoint], verbose=1)\n",
    "\n",
    "    model.load_weights(f\"{tag}_model.h5\")\n",
    "    evaluate_model(model, X_test, y_test, le, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6540558-415f-4b1b-8b8e-64b104a3e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training: Full_Model\n",
      "Epoch 1/100\n",
      "\u001b[1m 707/1319\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.2438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m     df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mObfuscated-MalMem2022.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pca\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_smote\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_attention\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFull_Model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(df, use_pca, use_smote, use_attention, tag)\u001b[39m\n\u001b[32m     10\u001b[39m model = build_model(input_dim, num_classes, use_attention)\n\u001b[32m     12\u001b[39m checkpoint = ModelCheckpoint(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model.h5\u001b[39m\u001b[33m\"\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m, monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m model.load_weights(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model.h5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m evaluate_model(model, X_test, y_test, le, tag)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"Obfuscated-MalMem2022.csv\")\n",
    "\n",
    "    run_experiment(df, use_pca=True, use_smote=True, use_attention=True, tag=\"Full_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66aa991e-cbee-47e8-8c56-82831bec04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training: Full_Multi_Model\n",
      "Epoch 1/100\n",
      "\u001b[1m 988/2637\u001b[0m \u001b[32mâ”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4530 - loss: 1.0180"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m     df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mObfuscated-MalMem2022-multi.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pca\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_smote\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_attention\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFull_Multi_Model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(df, use_pca, use_smote, use_attention, tag)\u001b[39m\n\u001b[32m     10\u001b[39m model = build_model(input_dim, num_classes, use_attention)\n\u001b[32m     12\u001b[39m checkpoint = ModelCheckpoint(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model.h5\u001b[39m\u001b[33m\"\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m, monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m model.load_weights(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model.h5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m evaluate_model(model, X_test, y_test, le, tag)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf219/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"Obfuscated-MalMem2022-multi.csv\")\n",
    "\n",
    "    run_experiment(df, use_pca=True, use_smote=True, use_attention=True, tag=\"Full_Multi_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2beb7c55-e3c6-4a08-8835-597b2b841468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training: Full_Multi_Model-2\n",
      "Epoch 1/100\n",
      "\u001b[1m671/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3660 - loss: 1.0867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 06:50:39.293109: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3662 - loss: 1.0866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 06:50:45.107042: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_158', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step - accuracy: 0.3662 - loss: 1.0866 - val_accuracy: 0.4374 - val_loss: 1.0332\n",
      "Epoch 2/100\n",
      "\u001b[1m674/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4409 - loss: 1.0421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4409 - loss: 1.0421 - val_accuracy: 0.4462 - val_loss: 1.0143\n",
      "Epoch 3/100\n",
      "\u001b[1m672/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4574 - loss: 1.0200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4575 - loss: 1.0199 - val_accuracy: 0.4753 - val_loss: 0.9956\n",
      "Epoch 4/100\n",
      "\u001b[1m675/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4969 - loss: 0.9774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4969 - loss: 0.9774 - val_accuracy: 0.5310 - val_loss: 0.9373\n",
      "Epoch 5/100\n",
      "\u001b[1m311/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5458 - loss: 0.9453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5432 - loss: 0.9401 - val_accuracy: 0.5559 - val_loss: 0.9098\n",
      "Epoch 6/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5710 - loss: 0.9000 - val_accuracy: 0.5489 - val_loss: 0.8861\n",
      "Epoch 7/100\n",
      "\u001b[1m669/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5884 - loss: 0.8784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5884 - loss: 0.8784 - val_accuracy: 0.5563 - val_loss: 0.8815\n",
      "Epoch 8/100\n",
      "\u001b[1m674/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5931 - loss: 0.8651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5932 - loss: 0.8651 - val_accuracy: 0.5975 - val_loss: 0.8533\n",
      "Epoch 9/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6131 - loss: 0.8379 - val_accuracy: 0.5813 - val_loss: 0.8416\n",
      "Epoch 10/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6147 - loss: 0.8268 - val_accuracy: 0.5896 - val_loss: 0.8451\n",
      "Epoch 11/100\n",
      "\u001b[1m674/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6255 - loss: 0.8107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6255 - loss: 0.8107 - val_accuracy: 0.6166 - val_loss: 0.8285\n",
      "Epoch 12/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 0.7944 - val_accuracy: 0.6150 - val_loss: 0.8207\n",
      "Epoch 13/100\n",
      "\u001b[1m676/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6425 - loss: 0.7869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6425 - loss: 0.7869 - val_accuracy: 0.6233 - val_loss: 0.8166\n",
      "Epoch 14/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6432 - loss: 0.7780 - val_accuracy: 0.6195 - val_loss: 0.8216\n",
      "Epoch 15/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6473 - loss: 0.7713 - val_accuracy: 0.6233 - val_loss: 0.8015\n",
      "Epoch 16/100\n",
      "\u001b[1m676/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6565 - loss: 0.7602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6564 - loss: 0.7602 - val_accuracy: 0.6249 - val_loss: 0.8040\n",
      "Epoch 17/100\n",
      "\u001b[1m674/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6636 - loss: 0.7465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6636 - loss: 0.7465 - val_accuracy: 0.6358 - val_loss: 0.8043\n",
      "Epoch 18/100\n",
      "\u001b[1m670/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6754 - loss: 0.7305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6752 - loss: 0.7306 - val_accuracy: 0.6362 - val_loss: 0.8086\n",
      "Epoch 19/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6692 - loss: 0.7357 - val_accuracy: 0.6312 - val_loss: 0.7853\n",
      "Epoch 20/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6822 - loss: 0.7132 - val_accuracy: 0.6279 - val_loss: 0.7955\n",
      "Epoch 21/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6757 - loss: 0.7227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6757 - loss: 0.7227 - val_accuracy: 0.6420 - val_loss: 0.7869\n",
      "Epoch 22/100\n",
      "\u001b[1m668/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6892 - loss: 0.7024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6891 - loss: 0.7025 - val_accuracy: 0.6445 - val_loss: 0.7732\n",
      "Epoch 23/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.6866 - val_accuracy: 0.6333 - val_loss: 0.8034\n",
      "Epoch 24/100\n",
      "\u001b[1m669/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6968 - loss: 0.6938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6967 - loss: 0.6939 - val_accuracy: 0.6482 - val_loss: 0.7882\n",
      "Epoch 25/100\n",
      "\u001b[1m672/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6953 - loss: 0.6828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6954 - loss: 0.6828 - val_accuracy: 0.6557 - val_loss: 0.8000\n",
      "Epoch 26/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6937 - loss: 0.6901 - val_accuracy: 0.6549 - val_loss: 0.7983\n",
      "Epoch 27/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7068 - loss: 0.6776 - val_accuracy: 0.6549 - val_loss: 0.8001\n",
      "Epoch 28/100\n",
      "\u001b[1m675/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7128 - loss: 0.6520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7128 - loss: 0.6521 - val_accuracy: 0.6599 - val_loss: 0.7859\n",
      "Epoch 29/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7108 - loss: 0.6659 - val_accuracy: 0.6462 - val_loss: 0.8095\n",
      "Epoch 30/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.6489 - val_accuracy: 0.6478 - val_loss: 0.7964\n",
      "Epoch 31/100\n",
      "\u001b[1m675/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.6344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.6345 - val_accuracy: 0.6636 - val_loss: 0.7719\n",
      "Epoch 32/100\n",
      "\u001b[1m667/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7185 - loss: 0.6462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7185 - loss: 0.6463 - val_accuracy: 0.6653 - val_loss: 0.7986\n",
      "Epoch 33/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7180 - loss: 0.6398 - val_accuracy: 0.6574 - val_loss: 0.7945\n",
      "Epoch 34/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.6265 - val_accuracy: 0.6595 - val_loss: 0.7695\n",
      "Epoch 35/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7258 - loss: 0.6361 - val_accuracy: 0.6570 - val_loss: 0.7724\n",
      "Epoch 36/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7314 - loss: 0.6215 - val_accuracy: 0.6611 - val_loss: 0.7955\n",
      "Epoch 37/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.6267 - val_accuracy: 0.6528 - val_loss: 0.8446\n",
      "Epoch 38/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7326 - loss: 0.6170 - val_accuracy: 0.6595 - val_loss: 0.8215\n",
      "Epoch 39/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.6045 - val_accuracy: 0.6557 - val_loss: 0.7887\n",
      "Epoch 40/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7499 - loss: 0.5927 - val_accuracy: 0.6607 - val_loss: 0.8123\n",
      "Epoch 41/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.5887 - val_accuracy: 0.6553 - val_loss: 0.8016\n",
      "Epoch 42/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7391 - loss: 0.6009 - val_accuracy: 0.6599 - val_loss: 0.8119\n",
      "Epoch 43/100\n",
      "\u001b[1m674/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7477 - loss: 0.5850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7477 - loss: 0.5851 - val_accuracy: 0.6665 - val_loss: 0.7931\n",
      "Epoch 44/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7521 - loss: 0.5859 - val_accuracy: 0.6636 - val_loss: 0.7806\n",
      "Epoch 45/100\n",
      "\u001b[1m672/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7514 - loss: 0.5866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7514 - loss: 0.5867 - val_accuracy: 0.6711 - val_loss: 0.8159\n",
      "Epoch 46/100\n",
      "\u001b[1m669/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7572 - loss: 0.5766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 0.5767 - val_accuracy: 0.6761 - val_loss: 0.8206\n",
      "Epoch 47/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7492 - loss: 0.5760 - val_accuracy: 0.6669 - val_loss: 0.8092\n",
      "Epoch 48/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7601 - loss: 0.5642 - val_accuracy: 0.6740 - val_loss: 0.8221\n",
      "Epoch 49/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 0.5691 - val_accuracy: 0.6707 - val_loss: 0.8090\n",
      "Epoch 50/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7561 - loss: 0.5777 - val_accuracy: 0.6703 - val_loss: 0.8318\n",
      "Epoch 51/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7531 - loss: 0.5668 - val_accuracy: 0.6611 - val_loss: 0.8429\n",
      "Epoch 52/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7583 - loss: 0.5677 - val_accuracy: 0.6590 - val_loss: 0.8387\n",
      "Epoch 53/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7569 - loss: 0.5706 - val_accuracy: 0.6711 - val_loss: 0.8195\n",
      "Epoch 54/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.5569 - val_accuracy: 0.6611 - val_loss: 0.8335\n",
      "Epoch 55/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7697 - loss: 0.5431 - val_accuracy: 0.6694 - val_loss: 0.7957\n",
      "Epoch 56/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7695 - loss: 0.5424 - val_accuracy: 0.6694 - val_loss: 0.8284\n",
      "Epoch 57/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7674 - loss: 0.5477 - val_accuracy: 0.6674 - val_loss: 0.8488\n",
      "Epoch 58/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7716 - loss: 0.5384 - val_accuracy: 0.6690 - val_loss: 0.8434\n",
      "Epoch 59/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.5416 - val_accuracy: 0.6644 - val_loss: 0.8271\n",
      "Epoch 60/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7733 - loss: 0.5341 - val_accuracy: 0.6753 - val_loss: 0.8367\n",
      "Epoch 61/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7710 - loss: 0.5337 - val_accuracy: 0.6707 - val_loss: 0.8190\n",
      "Epoch 62/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7799 - loss: 0.5178 - val_accuracy: 0.6740 - val_loss: 0.8029\n",
      "Epoch 63/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7781 - loss: 0.5263 - val_accuracy: 0.6682 - val_loss: 0.8666\n",
      "Epoch 64/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7821 - loss: 0.5200 - val_accuracy: 0.6719 - val_loss: 0.8985\n",
      "Epoch 65/100\n",
      "\u001b[1m667/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.5325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7772 - loss: 0.5324 - val_accuracy: 0.6848 - val_loss: 0.8582\n",
      "Epoch 66/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7797 - loss: 0.5213 - val_accuracy: 0.6757 - val_loss: 0.8280\n",
      "Epoch 67/100\n",
      "\u001b[1m672/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7749 - loss: 0.5302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7749 - loss: 0.5302 - val_accuracy: 0.6869 - val_loss: 0.8249\n",
      "Epoch 68/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7832 - loss: 0.5226 - val_accuracy: 0.6844 - val_loss: 0.8442\n",
      "Epoch 69/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7839 - loss: 0.5197 - val_accuracy: 0.6753 - val_loss: 0.8141\n",
      "Epoch 70/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.4973 - val_accuracy: 0.6778 - val_loss: 0.8527\n",
      "Epoch 71/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.5170 - val_accuracy: 0.6674 - val_loss: 0.8840\n",
      "Epoch 72/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7896 - loss: 0.4976 - val_accuracy: 0.6728 - val_loss: 0.9016\n",
      "Epoch 73/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.5129 - val_accuracy: 0.6802 - val_loss: 0.8757\n",
      "Epoch 74/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7910 - loss: 0.4996 - val_accuracy: 0.6769 - val_loss: 0.8650\n",
      "Epoch 75/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.5046 - val_accuracy: 0.6744 - val_loss: 0.8924\n",
      "Epoch 76/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7926 - loss: 0.5021 - val_accuracy: 0.6794 - val_loss: 0.8370\n",
      "Epoch 77/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.4978 - val_accuracy: 0.6769 - val_loss: 0.9182\n",
      "Epoch 78/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7761 - loss: 0.5693 - val_accuracy: 0.6736 - val_loss: 0.8236\n",
      "Epoch 79/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7902 - loss: 0.4986 - val_accuracy: 0.6848 - val_loss: 0.8122\n",
      "Epoch 80/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7899 - loss: 0.4938 - val_accuracy: 0.6802 - val_loss: 0.8517\n",
      "Epoch 81/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.4815 - val_accuracy: 0.6840 - val_loss: 0.8863\n",
      "Epoch 82/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7924 - loss: 0.4925 - val_accuracy: 0.6761 - val_loss: 0.8783\n",
      "Epoch 83/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.4805 - val_accuracy: 0.6782 - val_loss: 0.8913\n",
      "Epoch 84/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.4859 - val_accuracy: 0.6699 - val_loss: 0.8900\n",
      "Epoch 85/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7950 - loss: 0.4967 - val_accuracy: 0.6699 - val_loss: 0.9070\n",
      "Epoch 86/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8007 - loss: 0.4794 - val_accuracy: 0.6753 - val_loss: 0.9087\n",
      "Epoch 87/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.4849 - val_accuracy: 0.6832 - val_loss: 0.8987\n",
      "Epoch 88/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.4783 - val_accuracy: 0.6707 - val_loss: 0.9185\n",
      "Epoch 89/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8029 - loss: 0.4690 - val_accuracy: 0.6832 - val_loss: 0.9569\n",
      "Epoch 90/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.4749 - val_accuracy: 0.6703 - val_loss: 0.9340\n",
      "Epoch 91/100\n",
      "\u001b[1m667/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8004 - loss: 0.4715 - val_accuracy: 0.6886 - val_loss: 0.9439\n",
      "Epoch 92/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8024 - loss: 0.4655 - val_accuracy: 0.6840 - val_loss: 0.9421\n",
      "Epoch 93/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8041 - loss: 0.4683 - val_accuracy: 0.6802 - val_loss: 0.9587\n",
      "Epoch 94/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8020 - loss: 0.4647 - val_accuracy: 0.6728 - val_loss: 0.8939\n",
      "Epoch 95/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.4567 - val_accuracy: 0.6794 - val_loss: 0.9582\n",
      "Epoch 96/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.4633 - val_accuracy: 0.6852 - val_loss: 1.0358\n",
      "Epoch 97/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8077 - loss: 0.4577 - val_accuracy: 0.6836 - val_loss: 0.9306\n",
      "Epoch 98/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.4617 - val_accuracy: 0.6744 - val_loss: 1.0206\n",
      "Epoch 99/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8144 - loss: 0.4502 - val_accuracy: 0.6728 - val_loss: 1.0165\n",
      "Epoch 100/100\n",
      "\u001b[1m677/677\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8098 - loss: 0.4567 - val_accuracy: 0.6819 - val_loss: 0.9699\n",
      "\u001b[1m185/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 06:57:12.079478: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_120', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-07-07 06:57:12.104055: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_127', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-07-07 06:57:12.460555: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_127', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step\n",
      "\n",
      "ðŸ“Š Classification Report: Full_Multi_Model-2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Ransomware       0.68      0.64      0.66      2004\n",
      "     Spyware       0.70      0.76      0.73      2004\n",
      "Trojan Horse       0.70      0.69      0.69      2004\n",
      "\n",
      "    accuracy                           0.70      6012\n",
      "   macro avg       0.70      0.70      0.70      6012\n",
      "weighted avg       0.70      0.70      0.70      6012\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"Obfuscated-MalMem2022-multi-2.csv\")\n",
    "\n",
    "    run_experiment(df, use_pca=True, use_smote=True, use_attention=True, tag=\"Full_Multi_Model-2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf219",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
